### 项目概述
这是一个基于 UV 管理的小说可视化项目，目标是实现将小说生成视频的环节自动化，让创作者只需关注其中的几个关键点即可完成视频的生成。

### 工作流 0.01 版本
当前工作流假设小说人物肖像不会出现太大改动，以下是详细的工作流步骤：

#### 1. 文本预处理
- **任务 1.1**: 将小说按照章节分段，储存下来。
  - **需求**: 实现一个文本分段模块，能够将小说文本按照章节进行分段，并保存到数据库或文件中。
- **任务 1.2**: 大模型阅读小说，对于每一章进行分析，提取出重要的角色及其有关信息，按照一定方式储存，按照时间线总结分析主要次要人物，分析出哪些人物需要生成肖像以获得更好的观感，哪些人物的肖像可以直接临场生成。
  - **需求**: 集成大模型 API，实现文本分析功能，提取角色信息并存储。
- **任务 1.3**: 大模型根据对应信息，总结输出对应人物的肖像特征，并且整理成为图像生成模型的 prompt。
  - **需求**: 实现 prompt 生成模块，将角色信息转换为图像生成模型的输入格式。

#### 2. 肖像生成，建立角色特征数据库
- **任务 2.1**: 调用图像生成大模型对于肖像进行生成，并且人工审核后生成对应的肖像库，包含人物不同表情的照片，使用 IP Adapter 来生成 prompt，并且将 prompt 和对应的图片储存下来。
  - **需求**: 集成图像生成大模型 API，实现肖像生成功能，并支持人工审核。
- **任务 2.2**: 将以上数据库作为基础，建立角色特征数据库，用于后续的角色一致性。
  - **需求**: 设计并实现角色特征数据库，存储角色的肖像特征和相关 prompt。

#### 3. 音频处理
- **任务 3.1**: 直接按照对应图片切片，使用大模型进行文本转语音，生成对应的音频，音色使用最简单的方式。
  - **需求**: 集成文本转语音大模型 API，实现音频生成功能。

#### 4. 视频合成
- **任务 4.1**: 图片和音频按照时间线进行合成，生成对应的视频。
  - **需求**: 实现视频合成模块，能够将图片和音频按照时间线合成视频。
- **任务 4.2**: 图片直接使用最简单的动画，上下移动。
  - **需求**: 实现简单的动画效果，如上下移动。

### 模块解析
#### 系统性角色管理策略
1. **新场景需求**: 当有新的场景需求时，检查角色是否存在。
2. **角色存在?**: 如果角色存在，则提取特征向量和参考图；如果角色不存在，则新建角色档案。
3. **参数化约束**: 对提取的特征向量和参考图进行参数化约束。
4. **生成质量检测**: 检测生成的肖像质量。
5. **CLIP-I > 0.85?**: 如果 CLIP-I 的相似度大于 0.85，则输出；否则调整参考图权重并重新生成。

### 工具与模型
- **理论工具**:
  - CLIP 图文多模态模型
  - Midjourney 实现角色一致性
  - DALL-E 3 中的格子布局
  - IP Adapter 实现人物一致性
  - ControlNet 的 IP-Adapter 预处理器
  - StoryMaker
- **模型提供**:
  - 可灵
